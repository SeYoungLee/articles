{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-keras 이용하기\n",
    "\n",
    "안녕하세요? \n",
    "\n",
    "저는 데이터분석가로 일하고 있고, 최근에는 IoT 센서에서 수집된 데이터를 이용해 목적에 맞는 딥러닝 모델을 학습/분석하는 업무를 진행하고 있습니다.\n",
    "\n",
    "서비스의 요구사항에 맞게 머신러닝 모델을 학습할 때 가장 어려운 부분은 여러개의 비교가능한 모델을 학습하고, 어떤 모델 구조를 사용하는게 적합한지 의사결정하는 과정일 것입니다. task specific한 부분은 차치하더라도, 기존에 잘 알려진 모델을 자유자재로 잘 다루는 것도 어렵고.. 매일같이 자기들의 실험결과가 state-of-art 수준이라는 논문이 쏟아지니 혹시라도 내가 놓힌 부분이 있을지 불안하기도 합니다. \n",
    "\n",
    "분석할 시간이 충분하다면(분석가의 의지가 강하다면) 가능한 모든 구조를 학습하고 비교분석하는게 좋겠지만, 현실은 녹록치않습니다.\n",
    "주어진 데이터에 어떤 모델이 적합한지 꽤둟어볼수 있는 통찰력은 도대체 어떻게 얻을수 있는 걸까요?\n",
    "\n",
    "자기 반성은 이쯤하고... \n",
    "\n",
    "데이터에 적합한 모델을 자동으로 찾아준다는 오토ML 패키지가 나왔다고 하여 간단히 테스트해본 후기를 공유드립니다.\n",
    "\n",
    "* __*공식 문서 : https://autokeras.com/ *__\n",
    "* __*깃허브 : https://github.com/jhfjhfj1/autokeras *__\n",
    "\n",
    "### Auto-keras란?\n",
    "* Auto-Keras는 자동화된 기계 학습 (AutoML)을 위한 오픈 소스 소프트웨어 라이브러리입니다.\n",
    "* AutoML의 목표는 데이터 과학 또는 기계 학습에 대한 전문적인 배경지식없이 도메인 전문가가 손쉽게 딥러닝 모델을 학습할수 있도록 하는 것입니다.\n",
    "* Auto-Keras는 __*딥러닝모델의 아키텍처 및 하이퍼 파라미터를 자동으로 검색하는 기능*__ 을 제공합니다.\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "* torch 기반 패키지입니다. keras과 tensorflow 기반이 아니라니..ㅠ 제가 속았습니다.\n",
    "    * 코드를 살펴보니 현재는 벤치마크 데이터셋을 불러오는 부분에서만 keras를 사용하고 있습니다.\n",
    "    * auto-keras의 핵심인 searcher가 정확도가 더 높은 모델을 찾아 최적화하는 부분은 torch 기반으로 작성되어 있습니다.\n",
    "\n",
    "* 모델 탐색 결과를 저장하고, 다시 불러오고, 구조를 변경하여 학습할 수 있음을 확인하였습니다.\n",
    "    * torch를 잘 안다면.. 모델 학습 시간을 단축시킬수 있겠어요.\n",
    "    * 아직까진 분류 문제에 한해서요. \n",
    "\n",
    "* 딥러닝 전문가가 모델을 학습하는 것보다 더 좋은 성능의 모델 구조를 찾아내고 최적화된 파라미터를 학습할수 있을까요? (in other words, 우리 사장님이 저는 해고할 가능성이 있을까요?)\n",
    "    * 충분한 capacity(그러니까 GPU나 TPU같은 장비)가 주어져야할 것같아요. \n",
    "    * 더 고도화되면.. 향후엔 기계학습 리서처를 고용하는 대신에 GPU 장비를 더 사는게 경제적일지도 모르겠네요. ㅠㅠ \n",
    "\n",
    "# 0. 설치\n",
    "* pip install auto-keras\n",
    "    * python 3.6버전만 가능해요!\n",
    "* pip install git+git://github.com:jhfjhfj1/autokeras.git\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "\n",
    "* keras 패키지를 이용해 잘 알려진 벤치마크 데이터를 가지고 있거나, 개인이 가지고 있는 데이터를 이용할수 있습니다.\n",
    "* 저는 cifar10 데이터를 이용했습니다. \n",
    "* cifar10에 대한 주요 딥러닝 모델별 결과는 여기를 참고하세요.\n",
    "    * https://en.wikipedia.org/wiki/CIFAR-10\n",
    "    * DenseNet : 5.19 %, Wide ResNet : 4.0 %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from autokeras.classifier import ImageClassifier\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. classifer 정의와 학습\n",
    "\n",
    "* 오토-케라스를 구성하는 요소는 아래와 같습니다.\n",
    "    * 여러개의 분류기 모델가 있는 이데아 공간. 탐색해야 하는 space (이미지 분류기를 찾고자 해서 classifier인듯) : classifier\n",
    "    * 이데아 공간을 탐색하고 최적 모델 구조를 찾아가는 옵티마이저 : searcher\n",
    "    * 이데아 공간의 한 포인트에 대응되는 임의의 구조를 가진 컨볼루셔널 모델 : graph\n",
    "    * 임의 구조로 입력데이터에 적합하게 학습된 파라미터를 가진 실제 이미지 분류 모델 : model\n",
    "* 첫번째 할일은 우선 우리가 산책해야할 공간을 정의하는 것입니다. \n",
    "* 그리고 clf.fit()을 하면, 공간을 정의하고 이 공간에서 최적 model을 찾도록 searcher가 clf 공간을 막 돌아댕깁니다.\n",
    "* searcher가 한발자국 걸어가는 것은 아래와 같은 일이 일어나고 있다는 겁니다.\n",
    "    * 공간 내 한 포인트에 대응되는 그래프를 그리고, 그 그래프를 학습시킵니다. \n",
    "    * 이때 모델을 얼마나 학습시킬지, 얼마나 학습시켜보고 이 모델의 평가할지를 결정할수 있습니다. \n",
    "        * default 값은 아래와 같습니다. \n",
    "            * MAX_ITER_NUM = 200\n",
    "            * MIN_LOSS_DEC = 1e-4\n",
    "            * MAX_NO_IMPROVEMENT_NUM = 5\n",
    "        * https://github.com/jhfjhfj1/autokeras/blob/master/autokeras/utils.py#L102\n",
    "    * 저는 cpu만 있는 맥북에서 테스트를 하기때문에 각 모델별로 5 epoch만 학습하도록 하였습니다. \n",
    "        * epoch별 정확도는 주피터 노트북에 출력되지 않고, 주피터 로그에 출력이 됩니다.    \n",
    "<img src='epoch_acc.png' width=500></img>\n",
    "\n",
    "    * 최종적으로는 5 epoch 의 평균 정확도(출력된 Accuracy)가 모델의 평가 지표로 기록됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ImageClassifier(verbose=True, path='auto-keras/', searcher_args={'trainer_args':{'max_iter_num':5}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing search.\n",
      "Initialization finished.\n",
      "Training model  0\n",
      "Saving model.\n",
      "Model ID: 0\n",
      "Loss: tensor(3.3173)\n",
      "Accuracy 82.7872340425532\n",
      "Training model  1\n",
      "Father ID:  0\n",
      "[('to_wider_model', 6, 64)]\n",
      "Saving model.\n",
      "Model ID: 1\n",
      "Loss: tensor(3.0486)\n",
      "Accuracy 83.91489361702129\n",
      "Training model  2\n",
      "Father ID:  1\n",
      "[('to_wider_model', 11, 64)]\n",
      "Saving model.\n",
      "Model ID: 2\n",
      "Loss: tensor(3.0436)\n",
      "Accuracy 85.14893617021275\n",
      "Training model  3\n",
      "Father ID:  2\n",
      "[('to_wider_model', 6, 128)]\n",
      "Saving model.\n",
      "Model ID: 3\n",
      "Loss: tensor(2.9816)\n",
      "Accuracy 84.93617021276596\n",
      "Training model  4\n",
      "Father ID:  1\n",
      "[('to_wider_model', 6, 64)]\n",
      "Saving model.\n",
      "Model ID: 4\n",
      "Loss: tensor(2.9916)\n",
      "Accuracy 85.76595744680851\n",
      "Training model  5\n",
      "Father ID:  3\n",
      "[('to_wider_model', 6, 64)]\n",
      "Saving model.\n",
      "Model ID: 5\n",
      "Loss: tensor(2.9328)\n",
      "Accuracy 84.34042553191489\n",
      "Training model  6\n",
      "Father ID:  0\n",
      "[('to_wider_model', 1, 64), ('to_wider_model', 6, 64)]\n",
      "Saving model.\n",
      "Model ID: 6\n",
      "Loss: tensor(2.8635)\n",
      "Accuracy 84.82978723404256\n"
     ]
    }
   ],
   "source": [
    "clf.fit(x_train, y_train, time_limit = 2 * 60 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. clf의 final_fit\n",
    "\n",
    "* ddddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........\n",
      "Epoch 1: loss 14.130000114440918, accuracy 84.69979296066252\n",
      ".........\n",
      "Epoch 2: loss 13.873464584350586, accuracy 85.30020703933748\n",
      ".........\n",
      "Epoch 3: loss 14.748814582824707, accuracy 84.36853002070393\n",
      ".........\n",
      "Epoch 4: loss 13.878631591796875, accuracy 85.44513457556936\n",
      ".........\n",
      "Epoch 5: loss 13.748845100402832, accuracy 85.6728778467909\n",
      ".........\n",
      "Epoch 6: loss 13.842489242553711, accuracy 85.46583850931677\n",
      ".........\n",
      "Epoch 7: loss 14.11633586883545, accuracy 85.13457556935818\n",
      ".........\n",
      "Epoch 8: loss 13.74773120880127, accuracy 85.23809523809524\n",
      ".........\n",
      "Epoch 9: loss 14.272468566894531, accuracy 84.38923395445134\n",
      ".........\n",
      "Epoch 10: loss 14.081094741821289, accuracy 85.40372670807453\n",
      ".........\n",
      "Epoch 11: loss 14.25650691986084, accuracy 85.32091097308489\n",
      ".........\n",
      "Epoch 12: loss 13.47047233581543, accuracy 85.81780538302277\n",
      ".........\n",
      "Epoch 13: loss 13.515745162963867, accuracy 85.21739130434783\n",
      ".........\n",
      "Epoch 14: loss 14.218124389648438, accuracy 84.4927536231884\n",
      ".........\n",
      "Epoch 15: loss 13.876603126525879, accuracy 85.15527950310559\n",
      ".........\n",
      "Epoch 16: loss 17.803131103515625, accuracy 80.26915113871635\n",
      ".........\n",
      "Epoch 17: loss 13.56763744354248, accuracy 85.83850931677019\n",
      ".........\n",
      "Epoch 18: loss 15.81383228302002, accuracy 83.87163561076605\n",
      ".........\n",
      "Epoch 19: loss 14.330272674560547, accuracy 85.09316770186335\n",
      "No loss decrease after 5 epochs\n",
      "0.8463768115942029\n"
     ]
    }
   ],
   "source": [
    "clf.final_fit(x_train, y_train, x_test, y_test, retrain=False)\n",
    "y = clf.evaluate(x_test, y_test)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_best_model_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'auto-keras/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.path \n",
    "## default path is /tmp/autokeras/\n",
    "## if you want to change path, create clf with path pram.\n",
    "# clf = ImageClassifier(verbose=True, path='auto-keras-test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '4.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0dd5d0bb3076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'4.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '4.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_id': 0, 'loss': tensor(3.3173), 'accuracy': 82.7872340425532},\n",
       " {'model_id': 1, 'loss': tensor(3.0486), 'accuracy': 83.91489361702129},\n",
       " {'model_id': 2, 'loss': tensor(3.0436), 'accuracy': 85.14893617021275},\n",
       " {'model_id': 3, 'loss': tensor(2.9816), 'accuracy': 84.93617021276596},\n",
       " {'model_id': 4, 'loss': tensor(2.9916), 'accuracy': 85.76595744680851},\n",
       " {'model_id': 5, 'loss': tensor(2.9328), 'accuracy': 84.34042553191489},\n",
       " {'model_id': 6, 'loss': tensor(2.8635), 'accuracy': 84.82978723404256}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher = clf.load_searcher()\n",
    "searcher.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = searcher.load_best_model()\n",
    "model = graph.produce_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ReLU(),\n",
       " Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5)),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout2d(p=0.25),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " ReLU(),\n",
       " Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5)),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout2d(p=0.25),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " ReLU(),\n",
       " Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5)),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout2d(p=0.25),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " TorchFlatten(),\n",
       " Linear(in_features=1024, out_features=2, bias=True),\n",
       " LogSoftmax()]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_backend': <torch.nn.backends.thnn.THNNFunctionBackend at 0x1179a0208>,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('0', ReLU()),\n",
       "              ('1',\n",
       "               Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5))),\n",
       "              ('2',\n",
       "               BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "              ('3', Dropout2d(p=0.25)),\n",
       "              ('4',\n",
       "               MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
       "              ('5', ReLU()),\n",
       "              ('6',\n",
       "               Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5))),\n",
       "              ('7',\n",
       "               BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "              ('8', Dropout2d(p=0.25)),\n",
       "              ('9',\n",
       "               MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
       "              ('10', ReLU()),\n",
       "              ('11',\n",
       "               Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5))),\n",
       "              ('12',\n",
       "               BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
       "              ('13', Dropout2d(p=0.25)),\n",
       "              ('14',\n",
       "               MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)),\n",
       "              ('15', TorchFlatten()),\n",
       "              ('16', Linear(in_features=1024, out_features=2, bias=True)),\n",
       "              ('17', LogSoftmax())]),\n",
       " 'training': True,\n",
       " 'graph': <autokeras.graph.Graph at 0x1256eb780>,\n",
       " 'layers': [ReLU(),\n",
       "  Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5)),\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "  Dropout2d(p=0.25),\n",
       "  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       "  ReLU(),\n",
       "  Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5)),\n",
       "  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "  Dropout2d(p=0.25),\n",
       "  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       "  ReLU(),\n",
       "  Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5)),\n",
       "  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       "  Dropout2d(p=0.25),\n",
       "  MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       "  TorchFlatten(),\n",
       "  Linear(in_features=1024, out_features=2, bias=True),\n",
       "  LogSoftmax()]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ReLU(),\n",
       " Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5)),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout2d(p=0.25),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " ReLU(),\n",
       " Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5)),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout2d(p=0.25),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " ReLU(),\n",
       " Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1.5, 1.5)),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Dropout2d(p=0.25),\n",
       " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " TorchFlatten(),\n",
       " Linear(in_features=1024, out_features=2, bias=True),\n",
       " LogSoftmax()]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = ImageClassifier(verbose=True, path='auto-keras/', searcher_args={'trainer_args':{'max_iter_num':5}})\n",
    "searcher2 = clf2.load_searcher()\n",
    "graph2 = searcher2.load_best_model()\n",
    "model2 = graph2.produce_model()\n",
    "model2.layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
